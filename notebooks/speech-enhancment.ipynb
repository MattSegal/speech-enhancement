{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.datasets.speech_dataset import SpeechDataset\n",
    "from src.models.wave_u_net import WaveUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = 'wave-u-net-first-train-longer-1571448867.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 59/824 [00:00<00:01, 581.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation dataset into memory.\n",
      "Loading clean data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 824/824 [00:01<00:00, 486.03it/s]\n",
      "  7%|▋         | 56/824 [00:00<00:01, 546.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noisy data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 824/824 [00:01<00:00, 454.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading dataset into memory.\n"
     ]
    }
   ],
   "source": [
    "dataset = SpeechDataset(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoints/wave-u-net-first-train-longer-1571448867.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-caee0cdc4286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoints'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHECKPOINT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/speech-enhancement/speech-enhancement/env/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoints/wave-u-net-first-train-longer-1571448867.ckpt'"
     ]
    }
   ],
   "source": [
    "net = WaveUNet().cpu()\n",
    "net.eval()\n",
    "net.training\n",
    "checkpoint_path = os.path.join('checkpoints', CHECKPOINT)\n",
    "state_dict = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(arr, s):\n",
    "    print(s)\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=2)\n",
    "    fig.set_size_inches(12,12)\n",
    "    ax1.plot(arr)\n",
    "    ax2.specgram(arr, Fs=16000)    \n",
    "    plt.show()\n",
    "    return Audio(arr, rate=16000)\n",
    "\n",
    "def get_results(idx):\n",
    "    noisy_arr = dataset[idx][0].numpy()\n",
    "    clean_arr = dataset[idx][1].numpy()\n",
    "    inputs = torch.tensor(noisy_arr).float().cpu()\n",
    "    inputs = inputs.view(1, 1, -1)\n",
    "    outputs = net(inputs)\n",
    "    outputs = outputs.squeeze(dim=0).squeeze(dim=0)\n",
    "    pred_clean = outputs.cpu().detach().numpy()\n",
    "    pred_noise = noisy_arr - pred_clean\n",
    "    true_noise = noisy_arr - clean_arr\n",
    "    return noisy_arr, clean_arr, pred_clean, pred_noise, true_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_arr, clean_arr, pred_clean, pred_noise, true_noise = get_results(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(pred_clean, 'Predicted clean signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(noisy_arr, 'Noisy signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(clean_arr, 'Clean signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(pred_noise, 'Predicted noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(true_noise, 'True noise signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "TODO\n",
    " - find a better way to save audio / spectrogram for future reference\n",
    "\n",
    "- found audo clip start offsets were random - threw out older experiments\n",
    "- trained both MSE and FL on silence - worked OK\n",
    "- trained both MSE and FL on pass through (clean -> clean) - worked OK\n",
    "- tried to overfit small net on 1 batch - mostly just pass through\n",
    "- scaled up overfit net with MSE loss (100 epochs)\n",
    "  - 3 inner layers / 64 channels\n",
    "      - training\n",
    "        - loss diverges early from MSE 0.002 to 0.006 by epoch 4\n",
    "        - plateus for ~8 epochs\n",
    "        - slowly decreases to 0.0017 over ~90 epochs\n",
    "      - output\n",
    "        - legible, slightly distored, sounds a little clippy?\n",
    "        - waveform looks ok\n",
    "        - fine grained spectral details maintained\n",
    "  - 8 / 64: \n",
    "      - training diverges from 0.0014 to 0.005 in ~10 epochs\n",
    "      - plateaus for ~20 epochs\n",
    "      - doesn't really come down after that\n",
    "      - waveform looks noiser\n",
    "      - speech not legible\n",
    "  - 12/ 64:\n",
    " - scaled up overfit net with FL loss\n",
    "   - 3 inner layers, 64 channels\n",
    "       - training\n",
    "         - loss diverges early from 7 to 30 in first 10 epochs\n",
    "         - plateus for ~10 epochs\n",
    "         - slowly reduces to 16, MSE down to 0.0012 (slightly beating MSE loss)\n",
    "       - output\n",
    "         - waveform looks good!\n",
    "         - fine grained spectral detail mostly conserved\n",
    "         - noise is less\n",
    "         - voice a little splashly   \n",
    "   - 8 inner layers, 64 channels (100 epochs)\n",
    "       - training\n",
    "         - loss diverges early from 7 to 30 in first 10 epochs\n",
    "         - plateus for ~10 epochs\n",
    "         - slowly decreases to 24. MSE to 0.0045\n",
    "         - after 100 epochs down to 0.0012\n",
    "        - output\n",
    "          - waveform looks ok, some loss of fine grained detail\n",
    "          - spectrogam not noisy, but some loss of fine grained detail\n",
    "   - 12 inner layers, 64 channels (100 epochs)\n",
    "     - training\n",
    "     - output\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

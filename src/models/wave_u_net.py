import torch
import torch.nn as nn
from torch.utils.checkpoint import checkpoint_sequential

"""
We use the same VCTK dataset

ADAM optimization algorithm, a learning rate of 0.0001, decay rates β1 = 0.9 and β2 = 0.999
a batch size of 16.

We specify an initial network layer size of 12
16 extra filters per layer are also specified,
with downsampling block filters of size 15 and upsampling block filters of size 5 like in [12].

We train for 2,000 iterations with mean squared error (MSE) over all source output samples in a batch as
loss and apply early stopping if there is no improvement on the validation set for 20 epochs.

We use a fixed validation set of 10 randomly selected tracks. 

Then, the best model is fine-tuned with the batch size doubled and 
the learning rate lowered to 0.00001, again until 20 epochs have passed without
improved validation loss.

Under our implementation, training took c.36 hours using GeForce GTX 1080 Ti GPU with 11178 MiB

Train and test datasets provided by the 28-speaker 
[Voice Bank Corpus (VCTK)](https://datashare.is.ed.ac.uk/handle/10283/2791) [4]
(30 speakers in total - 28 intended for training and 2 reserved for testing).
 The noisy training data were generated by mixing the clean data with various noise datasets, 
 as per the instructions provided in [4, 5, 6].



audio-based MSE loss and mono
signals downsampled to 8192 Hz

look into https://github.com/pytorch/audio
for
    data loading
    audio transforms
    resampling
"""


class WaveUNet(nn.Module):
    """
    Convolutional neural net for speech enhancement
    Proposed in Improved Speech Enhancement with the Wave-U-Net (https://arxiv.org/pdf/1811.11307.pdf),
    which was in turn inspired by this paper (https://arxiv.org/pdf/1806.03185.pdf)
    """

    def __init__(self):
        super().__init__()
        # Construct downsampling sequence
        # out = in - filter + 1
        self.ds_conv_1 = DownSampleConvLayer(1, 1 * 24)
        self.ds_conv_2 = DownSampleConvLayer(1 * 24, 2 * 24)
        self.ds_conv_3 = DownSampleConvLayer(2 * 24, 3 * 24)
        self.ds_conv_4 = DownSampleConvLayer(3 * 24, 4 * 24)
        self.ds_conv_5 = DownSampleConvLayer(4 * 24, 5 * 24)
        self.ds_conv_6 = DownSampleConvLayer(5 * 24, 6 * 24)
        self.ds_conv_7 = DownSampleConvLayer(6 * 24, 7 * 24)
        self.ds_conv_8 = DownSampleConvLayer(7 * 24, 8 * 24)
        self.ds_conv_9 = DownSampleConvLayer(8 * 24, 9 * 24)
        self.ds_conv_10 = DownSampleConvLayer(9 * 24, 10 * 24)
        self.ds_conv_11 = DownSampleConvLayer(10 * 24, 11 * 24)
        self.ds_conv_12 = DownSampleConvLayer(11 * 24, 12 * 24)

        self.md_conv = MiddleConvLayer(12 * 24, 13 * 24)

        self.us_conv_1 = UpSampleConvLayer(13 * 24, 12 * 24)
        self.us_conv_2 = UpSampleConvLayer(12 * 24, 11 * 24)
        self.us_conv_3 = UpSampleConvLayer(11 * 24, 10 * 24)
        self.us_conv_4 = UpSampleConvLayer(10 * 24, 9 * 24)
        self.us_conv_5 = UpSampleConvLayer(9 * 24, 8 * 24)
        self.us_conv_6 = UpSampleConvLayer(8 * 24, 7 * 24)
        self.us_conv_7 = UpSampleConvLayer(7 * 24, 6 * 24)
        self.us_conv_8 = UpSampleConvLayer(6 * 24, 5 * 24)
        self.us_conv_9 = UpSampleConvLayer(5 * 24, 4 * 24)
        self.us_conv_10 = UpSampleConvLayer(4 * 24, 3 * 24)
        self.us_conv_11 = UpSampleConvLayer(3 * 24, 2 * 24)
        self.us_conv_12 = UpSampleConvLayer(2 * 24, 1 * 24)

        self.out_conv = OutputConvLayer(24, 1)

    def forward(self, input_t):
        """
        Input has shape (batch_size, 1, audio_length,) 
        Output has shape (batch_size, 2, audio_length,) 

        Fc = 24 extra filters
        per layer and filter sizes fd = 15 and fu = 5
        """
        # (batch, 1, 16384)
        # Downsampling
        acts, ds_acts_1 = self.ds_conv_1(input_t)
        acts, ds_acts_2 = self.ds_conv_2(acts)
        acts, ds_acts_3 = self.ds_conv_3(acts)
        acts, ds_acts_4 = self.ds_conv_4(acts)
        acts, ds_acts_5 = self.ds_conv_5(acts)
        acts, ds_acts_6 = self.ds_conv_6(acts)
        acts, ds_acts_7 = self.ds_conv_7(acts)
        acts, ds_acts_8 = self.ds_conv_8(acts)
        acts, ds_acts_9 = self.ds_conv_9(acts)
        acts, ds_acts_10 = self.ds_conv_10(acts)
        acts, ds_acts_11 = self.ds_conv_11(acts)
        acts, ds_acts_12 = self.ds_conv_12(acts)
        # (batch, 288, 4)

        acts = self.md_conv(acts)
        # (batch, 312, 4)

        # Upsampling
        acts = self.us_conv_1(md_acts, ds_acts_12)
        acts = self.us_conv_2(acts, ds_acts_11)
        acts = self.us_conv_3(acts, ds_acts_10)
        acts = self.us_conv_4(acts, ds_acts_9)
        acts = self.us_conv_5(acts, ds_acts_8)
        acts = self.us_conv_6(acts, ds_acts_7)
        acts = self.us_conv_7(acts, ds_acts_6)
        acts = self.us_conv_8(acts, ds_acts_5)
        acts = self.us_conv_9(acts, ds_acts_4)
        acts = self.us_conv_10(acts, ds_acts_3)
        acts = self.us_conv_11(acts, ds_acts_2)
        acts = self.us_conv_12(acts, ds_acts_1)

        # concat input
        # (batch, 24, 16384)
        output_t = self.out_conv(acts, input_t)
        # (batch, 25, 16384)
        # (batch, 2, 16384) (or 1, 3, 5, etc.)
        # conv1d with K output channels
        return output_t


class DownSampleConvLayer(nn.Module):
    """
    Single convolutional layer for downsampling
    """

    def __init__(self, in_channels, out_channels):
        """
        Setup the layer.
            in_channels: number of input channels to be convoluted
            out_channels: number of output channels to be produced

        """
        super().__init__()
        self.conv = nn.Conv1d(
            in_channels=in_channels,
            out_channels=out_channels,
            # padding=1,  # TODO - figure out how to zero pad properly.
            kernel_size=15,
            bias=True,
        )
        # Apply Kaiming initialization to convolutional weights
        nn.init.xavier_uniform_(self.conv.weight)
        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)

    def forward(self, input_t):
        """
        Compute output tensor from input tensor
        """
        conv_t = self.conv(input_t)
        relu_t = self.leaky_relu(norm_t)
        # Decimate discards features for every other time step to halve the time resolution
        decimated_t = relu_t[:, :, ::2]
        return decimated_t, relu_t


class MiddleConvLayer(nn.Module):
    def __init__(self, in_channels, out_channels):
    """
    Setup the layer.
        in_channels: number of input channels to be convoluted
        out_channels: number of output channels to be produced

    """
    super().__init__()
    self.conv = nn.Conv1d(
        in_channels=in_channels,
        out_channels=out_channels,
        # padding=1,  # TODO - figure out how to zero pad properly.
        kernel_size=15,
        bias=True,
    )
    # Apply Kaiming initialization to convolutional weights
    nn.init.xavier_uniform_(self.conv.weight)
    self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)

    def forward(self, input_t):
        """
        Compute output tensor from input tensor
        """
        conv_t = self.conv(input_t)
        relu_t = self.leaky_relu(norm_t)
        return relu_t


class UpSampleConvLayer(nn.Module):
    """
    Single convolutional layer for upsampling
    """

    def __init__(self, in_channels, out_channels):
        """
        Setup the layer.
            in_channels: number of input channels to be convoluted
            out_channels: number of output channels to be produced

        """
        super().__init__()
        self.conv = nn.Conv1d(
            in_channels=in_channels,
            out_channels=out_channels,
            kernel_size=5,
            bias=True,
        )
        # Apply Kaiming initialization to convolutional weights
        nn.init.xavier_uniform_(self.conv.weight)
        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)

    def forward(self, input_t, sister_t):
        """
        Compute output tensor from input tensor
        """
        # Upsample performs upsampling in the time direction by a
        # factor of two, for which we use linear interpolation

        # TODO  - upsample
        # Concat(x) concatenates the current,
        # high-level features with more local features x

        # In extensions
        # of the base architecture (see below), where Conv1D does
        # not involve zero-padding, x is centre-cropped first so it has
        # the same number of time steps as the current layer.

        # TODO - concat sister block
        conv_t = self.conv(input_t)
        relu_t = self.leaky_relu(norm_t)
        return relu_t


class OutputConvLayer(nn.Module):
    """
    Single convolutional layer for output
    """

    def __init__(self, in_channels, out_channels):
        """
        Setup the layer.
            in_channels: number of input channels to be convoluted
            out_channels: number of output channels to be produced

        """
        super().__init__()
        self.conv = nn.Conv1d(
            in_channels=in_channels,
            out_channels=out_channels,
            kernel_size=1,
            bias=True,
        )
        # Apply Kaiming initialization to convolutional weights
        nn.init.xavier_uniform_(self.conv.weight)
        self.tanh = nn.Tanh()

    def forward(self, input_t, sister_t):
        """
        Compute output tensor from input tensor
        """
        # concat input_t and sister_t
        conv_t = self.conv(input_t)
        relu_t = self.tanh(conv_t)
        return relu_t
